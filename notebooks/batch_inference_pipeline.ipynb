{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Inference Pipeline\n",
    "\n",
    "In this notebook, we will do the following tasks:\n",
    "1. Create a batch inference pipeline using the pre-trained model.\n",
    "2. Run the pipeline and get the predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the.env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the environment variables\n",
    "hopsworks_api_key = os.getenv(\"HOPSWORKS_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-22 12:57:07,116 INFO: Initializing external client\n",
      "2025-02-22 12:57:07,125 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-02-22 12:57:10,615 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1212597\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login(api_key_value=str(hopsworks_api_key))\n",
    "fs = project.get_feature_store()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the model from model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = project.get_model_registry()\n",
    "\n",
    "EVALUATION_METRIC=\"mean_squared_error\"  \n",
    "SORT_METRICS_BY=\"min\" # your sorting criteria\n",
    "\n",
    "# get best model based on custom metrics\n",
    "best_model = mr.get_best_model(\"amazon_stock_price_prediction_model_torch\",\n",
    "                               EVALUATION_METRIC,\n",
    "                               SORT_METRICS_BY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 1 files)... DONE\r"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model\n",
    "model_dir = \"../models/amazon_stock_price_prediction_model_torch\"\n",
    "best_model.download(model_dir)\n",
    "state_dict = torch.load(f\"{model_dir}/model.pt\", weights_only=True)\n",
    "\n",
    "\n",
    "with open(\"../preprocessor/hyper_params.json\", \"r\") as f:\n",
    "    hyper_params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "import torch\n",
    "from torch import nn\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int, num_layers: int, device:str = 'cpu'):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "        \n",
    "\t\t# LSTM layer\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "\t# forward pass\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(self.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(self.device)\n",
    "        \n",
    "        out, (_, _) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMModel(input_dim=hyper_params['input_size'], hidden_dim=hyper_params['hidden_size'], output_dim=hyper_params['forecast_steps'], num_layers=hyper_params['num_layers'], device='cpu').to('cpu')\n",
    "\n",
    "# Load the trained model state_dict\n",
    "model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Feature view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-22 12:57:16,634 WARNING: VersionWarning: No version provided for getting feature view `amazon_fv`, defaulting to `1`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "amazon_fv = fs.get_feature_view(\"amazon_fv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.52s) \n"
     ]
    }
   ],
   "source": [
    "batch_data = amazon_fv.get_batch_data()\n",
    "\n",
    "\n",
    "# get the last 24 days of data for window_size\n",
    "sample  = batch_data.sort_values('date').drop('date', axis=1).tail(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4240</th>\n",
       "      <td>2025-02-21 15:00:00+00:00</td>\n",
       "      <td>220.830</td>\n",
       "      <td>221.16</td>\n",
       "      <td>219.395</td>\n",
       "      <td>218.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>2025-02-21 16:00:00+00:00</td>\n",
       "      <td>219.395</td>\n",
       "      <td>219.76</td>\n",
       "      <td>218.875</td>\n",
       "      <td>218.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4239</th>\n",
       "      <td>2025-02-21 17:00:00+00:00</td>\n",
       "      <td>218.875</td>\n",
       "      <td>218.90</td>\n",
       "      <td>216.965</td>\n",
       "      <td>216.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4238</th>\n",
       "      <td>2025-02-21 18:00:00+00:00</td>\n",
       "      <td>216.955</td>\n",
       "      <td>217.05</td>\n",
       "      <td>215.770</td>\n",
       "      <td>215.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>2025-02-21 19:00:00+00:00</td>\n",
       "      <td>215.790</td>\n",
       "      <td>216.15</td>\n",
       "      <td>215.465</td>\n",
       "      <td>214.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>2025-02-21 20:00:00+00:00</td>\n",
       "      <td>215.460</td>\n",
       "      <td>216.83</td>\n",
       "      <td>216.610</td>\n",
       "      <td>215.355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date     open    high    close      low\n",
       "4240 2025-02-21 15:00:00+00:00  220.830  221.16  219.395  218.075\n",
       "4241 2025-02-21 16:00:00+00:00  219.395  219.76  218.875  218.540\n",
       "4239 2025-02-21 17:00:00+00:00  218.875  218.90  216.965  216.550\n",
       "4238 2025-02-21 18:00:00+00:00  216.955  217.05  215.770  215.520\n",
       "4237 2025-02-21 19:00:00+00:00  215.790  216.15  215.465  214.755\n",
       "4236 2025-02-21 20:00:00+00:00  215.460  216.83  216.610  215.355"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "batch_data['date'] = pd.to_datetime(batch_data['date'], utc=True)\n",
    "\n",
    "batch_data = batch_data.sort_values('date')\n",
    "\n",
    "batch_data.tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    outputs = model(torch.tensor(np.array(sample)).float().unsqueeze(0).to('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = outputs.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataframe_image as dfi\n",
    "import pandas as pd\n",
    "\n",
    "time_stamps = batch_data.tail(6)['date'].dt.time.values[::-1]\n",
    "\n",
    "df = pd.DataFrame(outputs, columns=[\"Predicted\"])\n",
    "df = df.set_index(time_stamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20:00:00</th>\n",
       "      <td>180.487335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19:00:00</th>\n",
       "      <td>180.502701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18:00:00</th>\n",
       "      <td>180.586243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17:00:00</th>\n",
       "      <td>180.482452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16:00:00</th>\n",
       "      <td>180.519226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15:00:00</th>\n",
       "      <td>180.586624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted\n",
       "20:00:00  180.487335\n",
       "19:00:00  180.502701\n",
       "18:00:00  180.586243\n",
       "17:00:00  180.482452\n",
       "16:00:00  180.519226\n",
       "15:00:00  180.586624"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
